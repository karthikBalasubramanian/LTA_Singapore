{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How are Taxis enhancing the Singapore's Public Transport System.\n",
    "\n",
    "## Introduction\n",
    "Bus and rail system have fixed routes and schedules. Therefore they have deterministic coverage patterns which meet the general transportation demand. Taxicabs and ride sharing services do not have fixed routes or schedules thus in some sense, they meet the \"ad hoc\" demands. The goal of the project is to see if the supply pattern of taxicabs fill the gaps in the public transport network thereby enhancing it. \n",
    "The study would be done for Singapore, a city state which provides plentiful data for the public transport network. While public transport modelling has been done before, to the best of our knowledge, there have not been an analysis of taxis and public transport together.\n",
    "\n",
    "## Existing Work\n",
    "\n",
    "1. Singapore in Motion: Insights on Public Transport Service Level Through Farecard and Mobile Data Analytics, IBM 2016\n",
    "http://www.kdd.org/kdd2016/papers/files/SingaporeInMotion_v3.pdf\n",
    "2. Time-Series Data Mining in Transportation: A Case Study on Singapore Public Train Commuter Travel Patterns, SMU 2014 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got inspired from two projects and the papers that we presented as existing work. The projects are developed and made open source for commuters to use. They are.\n",
    "   \n",
    "   \n",
    "   1. [Taxi Router SG](https://github.com/cheeaun/taxirouter-sg) by [Lim Chee Aun](https://twitter.com/cheeaun). Its primary idea was to showcase the following details\n",
    "       \n",
    "       * Taxi stands in Singapore.\n",
    "       * Shows all available taxis in the whole Singapore.\n",
    "       * How many available taxis around the commuter?\n",
    "       * How far is the nearest taxi stand around the commuter?\n",
    "\n",
    "   2. [TaxiSg](http://uzyn.github.io/taxisg/) by [U-Zyn Chua](https://twitter.com/uzyn). This app helps the commuter to understand the distribution of taxis during a historic window (ranging from 15 minutes to 2 weeks of historic data).\n",
    "   \n",
    "   \n",
    "   Both the apps get their data from a government organisation called, The Land Transport Authority (LTA) of Singapore. LTA publishes a wide variety of transport-related datasets (static and dynamic / realtime) on their DataMall platform for enterprises, third-party developers, and other members of the public to promote citizen co-creation of innovative and inclusive transport solutions. Detailed description of the APIs can be found here.\n",
    "  \n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "   We wanted to answer the following questions and provide inferences based on our results.\n",
    "   \n",
    "   1. Is there a difference between the density distribution of taxis (AdHoc Requests made by commuters) and Bus/Rail network (Planned Transportation network) over the period of time?\n",
    "   \n",
    "   2. Are the taxis really trying to fill the gaps of the public transport system? (Fully loaded buses)\n",
    "   \n",
    "   3. Is there any change in the distribution of taxis vs Public transport system between weekdays and weekends? Statistically decide on a location (identify top ten location) and KL divergence on Relative frequencies of bus vs taxi during the window/ for the whole day\n",
    "   \n",
    "   \n",
    "   4. Can the Taxi demand be predicted based on previous patterns observed from the Taxi/Bus Density distribution? How precise can the prediction be in terms of time/location.\n",
    "   Try [Auto Regression](http://machinelearningmastery.com/autoregression-models-time-series-forecasting-python/) \n",
    "  \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sets\n",
    "2 dynamic data sets are collected were collected using the API between 03/15/2017 to 03/19/2017.\n",
    "\n",
    "1. Taxi Availability \n",
    "2. Bus Arrival\n",
    "\n",
    "2 static data was collected\n",
    "1. Urban Land Authority Master Planning Sub Zone 2014\n",
    "2. MRT train schedule (work in progress)\n",
    "\n",
    "The URA Zone codes were use to determine the usage of land, whether is it for commercial or residential etc.\n",
    "<img src=\"images/ura_2014.png\" width='500pix'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxi Availability Dataset\n",
    "\n",
    "### Description\n",
    "Returns location coordinates of all Taxis that are currently available for hire. Does not include \"Hired\" or \"Busy\" Taxis. We polled the API every *1min* for this dataset. A total of **40982444** location records were collected.\n",
    "                                                                                                             \n",
    "| **Attributes** \t| **Description**                                                    \t|\n",
    "|----------------\t|--------------------------------------------------------------------\t|\n",
    "| Latitude       \t| provides the latitude of the location where the taxi is available  \t| \n",
    "| Longitude      \t| provides the longitude of the location where the taxi is available \t| \n",
    "| Date           \t| provides the date when the taxi was available                      \t| \n",
    "| Time           \t| provides when the time was available                               \t| \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bus Arrival Dataset\n",
    "\n",
    "### Description\n",
    "Returns real-time Bus Arrival information for Bus Services at a queried Bus Stop, including: Estimated Time of Arrival (ETA), Estimated Location, Load info. We polled the API all over the bus stops in Singapore every *6min* for this dataset. A total of **6394212** bus stop arrival records were collected.\n",
    "\n",
    "                                                                                                                 \n",
    "| **Attributes**    | **Description**                                                       |\n",
    "|----------------   |--------------------------------------------------------------------   |\n",
    "| ServiceNo         | Bus service number   | \n",
    "| Status         | Bus Status    | \n",
    "| Latitude | Estimated location coordinates of bus |\n",
    "| Longtitude | Estimated location coordinates of bus |\n",
    "|Load|  Bus occupancy / crowding: Seats Available, Standing Available, Limited Standing|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "[hui han]\n",
    "### LTA Datamall\n",
    "\n",
    "### Dates of Collection\n",
    "in SG time\n",
    "14/3/17 - 19/4/17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling transportation flow\n",
    "\n",
    "### Projection from Lat Lon to UTM [hui han] \n",
    "   We wanted to change the projection from the regular (Latitude,Longitude) to Universal Transverse Mercator(UTM) for our project. You can find out the basics of  UTM [here](http://gisgeography.com/utm-universal-transverse-mercator-projection/). The primary reason for our decision is to avoid representing the Geo Locations in a distorted manner. UTM is also the best format to project for narrow Geo-locational area with high density details. \n",
    "\n",
    "### Density Estimation\n",
    "       \n",
    "   We had data collected for a five day period. To answer all the questions in our problem statement, we had to start with a Kernel Density estimation of Taxis and Buses for a window (10 minute window) slided over a period of five days. Kernel Desity Estimation will help us to identify the latent distribution from which the Taxi and Bus data originate. Also, Knowledge of the Distribution would help us to predict the taxis in the future based on the historic allocation of taxis and buses. We initially collected a random 10 minute sample of Bus Data and Taxi Data (for the same dates) and plotted Distribution of the Random sample. Before getting into the design decisions to formulate algorithm, we identified an outlier in the dataset.\n",
    "   \n",
    "\n",
    "### Outlier Removal \n",
    "\n",
    "  The Changi Airport is one of the biggest Taxi hub in Singapore. You could see from the figure that, the data is concentrated in the Airport area. When we remove the Airports area from equation, we see many hotspot locations in the sampled dataset.\n",
    "  \n",
    "  images go here.\n",
    "\n",
    "\n",
    "### Different Kernel Density Estimation\n",
    "[Karthik]\n",
    "  \n",
    "  Before we show you how distributions of Taxis and Kernel Densities are basically a generalised version of a Histogram. Its non-parametric, which means that we don't have any belief about from which distribution the data has come from.We will walk you through the problem that we are trying to solve.\n",
    "  \n",
    "  Lets say for example, We have a simple 2d Histogram with x axis being value and y axis being frequency, We can see the following problems with histogram\n",
    "  \n",
    "  1. histogram is prone to change by changing starting and ending points\n",
    "  2. Its not smooth\n",
    "  3. Provides a different interpretation for different bandwidths.\n",
    "  \n",
    "  \n",
    "   <img src=\"images/hist1.png\" width=\"300px\" style=\"float:left\"><img src=\"images/hist2.png\" width=\"300px\">\n",
    "   \n",
    "   Kernel Densities solve two of the three problems. \n",
    "   \n",
    "   1. Kernel Densities are not pro\n",
    "   \n",
    "   \n",
    "  \n",
    "  \n",
    "\n",
    "\n",
    "### Generating large scale KDE \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "### Comparison of Transport Densities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demand Estimation\n",
    "### Prediction Model \n",
    "[hui han]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxi API Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/home/bks4line/anaconda2/bin/python\n",
    "# Author : Karthik Balasubramanian\n",
    "\n",
    "import json\n",
    "import urllib\n",
    "from urlparse import urlparse\n",
    "import httplib2 as http #External library\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "import os\n",
    "#  please get your account keys and place here\n",
    "headers = { 'AccountKey' : 'XXXXX','accept' : 'application/json'}\n",
    "\n",
    "uri = 'http://datamall2.mytransport.sg/' #Resource URL\n",
    "path = 'ltaodataservice/Taxi-Availability?$skip='\n",
    "fmt =  '%Y-%m-%d_%H:%M:%S'\n",
    "sg = timezone('Asia/Singapore')\n",
    "my_path = %pwd\n",
    "dir_path = my_path+\"/data\"\n",
    "\n",
    "\n",
    "\n",
    "def get_data_from_LTA(filename):\n",
    "    \n",
    "    global headers,uri,path,fmt,sg,dir_path\n",
    "\n",
    "    \n",
    "    #Build query string & specify type of API call\n",
    "    \n",
    "    final_list = []\n",
    "    target = urlparse(uri + path+str(len(final_list)))\n",
    "\n",
    "    \n",
    "    \n",
    "    method = 'GET'\n",
    "    body = ''\n",
    "\n",
    "    #Get handle to http\n",
    "    h = http.Http()\n",
    "    \n",
    "    # Obtain results\n",
    "    response, content = h.request(target.geturl(),method,body,headers)\n",
    "\n",
    "    # Parse JSON to print\n",
    "    jsonObj = json.loads(content)\n",
    "    \n",
    "    final_list.extend(jsonObj[\"value\"])\n",
    "    \n",
    "    while(len(jsonObj[\"value\"])>0):\n",
    "        target = urlparse(uri + path+str(len(final_list)))\n",
    "        # print target.geturl()\n",
    "        response, content = h.request(target.geturl(),method,body,headers)\n",
    "        jsonObj = json.loads(content)\n",
    "        final_list.extend(jsonObj[\"value\"])\n",
    "    \n",
    "    \n",
    "    time_now_in_sg = datetime.now(sg)\n",
    "    date_and_time_ff =  time_now_in_sg.strftime(fmt)\n",
    "    date_and_time = date_and_time_ff.split(\"_\")\n",
    "    date_in_sg = [date_and_time[0]]*len(final_list)\n",
    "    time_in_sg =  [date_and_time[1]]*len(final_list)\n",
    "    \n",
    "    df = pd.DataFrame(final_list)\n",
    "    df['date'] = pd.Series(date_in_sg, index=df.index)\n",
    "    df['time'] = pd.Series(time_in_sg, index=df.index)\n",
    "    \n",
    "    if not filename:\n",
    "        filename =  dir_path+\"/taxi_\"+date_and_time_ff+\".csv\"\n",
    "        df.to_csv(filename)\n",
    "    else:\n",
    "        file_size_exceed = float(os.path.getsize(filename))/float(5e+6)\n",
    "        if file_size_exceed>1.0:\n",
    "            print \"file_size_exceed\"\n",
    "            filename = dir_path+\"/taxi_\"+date_and_time_ff+\".csv\"\n",
    "            print \"new file name {0}\".format(filename)\n",
    "            df.to_csv(filename)\n",
    "        else:\n",
    "            print \"file size not exceeded\"\n",
    "            df.to_csv(filename, mode='a', header=False)\n",
    "\n",
    "    return filename\n",
    "\n",
    "\n",
    "#  run the below code \n",
    "\n",
    " \n",
    "# starttime =  time.time()\n",
    "# filename = None\n",
    "# # get_data_from_LTA(filename=None)\n",
    "# while True:\n",
    "#     filename = get_data_from_LTA(filename)\n",
    "#     starttime =  time.mktime(datetime.now().timetuple())\n",
    "#     time.sleep(50.0 - ((time.time() - starttime) % 60.0))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
